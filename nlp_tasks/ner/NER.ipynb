{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "302da2af74444b6989883fb97ec5851c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_85292428dca6475c838466090d7e55f1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f75477712e5743e3aebef192664d9eba",
              "IPY_MODEL_0a6af3592f534589a2440e7e212d5c7c"
            ]
          }
        },
        "85292428dca6475c838466090d7e55f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f75477712e5743e3aebef192664d9eba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fb228d14bed344e5a1467e6cf0b04347",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_634aa3c5777242ce9fba2d27533bc5eb"
          }
        },
        "0a6af3592f534589a2440e7e212d5c7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1722e29bf20747f385ea01dc1173ba27",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 1.21kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1ead1fe8c1ca4a589cb83136f4dc9f4c"
          }
        },
        "fb228d14bed344e5a1467e6cf0b04347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "634aa3c5777242ce9fba2d27533bc5eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1722e29bf20747f385ea01dc1173ba27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1ead1fe8c1ca4a589cb83136f4dc9f4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c47efe53d2314e33a8841d8301975d87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bcb65e11e2ac4775a5a872f068ed918d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_db40df458a924ee3aea66cb39c260b75",
              "IPY_MODEL_83c1ea35d21445a1a2d7de700c14ebef"
            ]
          }
        },
        "bcb65e11e2ac4775a5a872f068ed918d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db40df458a924ee3aea66cb39c260b75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f8f6c37791294c7b9cc2d965f7ecc406",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c7d2fa885cb7494297bff33dc37acf40"
          }
        },
        "83c1ea35d21445a1a2d7de700c14ebef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6eb1a033374443cd8b6a9ef454fdd1e6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 842kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_45b388f133074941b3a4717f93af46fe"
          }
        },
        "f8f6c37791294c7b9cc2d965f7ecc406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c7d2fa885cb7494297bff33dc37acf40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6eb1a033374443cd8b6a9ef454fdd1e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "45b388f133074941b3a4717f93af46fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b745333e6bb840a093adf602d420a82e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_73fcbf9eba0e42c8a442f65c484b09d9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9582ac09d22b45dd9cd457cfdac8b330",
              "IPY_MODEL_eb992faa6b65467099a1c4da15a2268a"
            ]
          }
        },
        "73fcbf9eba0e42c8a442f65c484b09d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9582ac09d22b45dd9cd457cfdac8b330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d6ff8e97851f45a388c8c655e66eb496",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435797,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435797,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cb1634601e1741c788e440e84c650f49"
          }
        },
        "eb992faa6b65467099a1c4da15a2268a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9bec44b2ce7748b08f829256dd804ad1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436k/436k [00:29&lt;00:00, 14.9kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_25fdeafc632d4e3286210e378363dd49"
          }
        },
        "d6ff8e97851f45a388c8c655e66eb496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cb1634601e1741c788e440e84c650f49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9bec44b2ce7748b08f829256dd804ad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "25fdeafc632d4e3286210e378363dd49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5106b73dbaeb4559afe06f0216f77b9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_45de8fd6877147c387c1d59146d0a4c2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bd9e1a67829e498eaa910da673b3a446",
              "IPY_MODEL_3d047ba32cb741b6822f5c9a3d8073c7"
            ]
          }
        },
        "45de8fd6877147c387c1d59146d0a4c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd9e1a67829e498eaa910da673b3a446": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_81a2dc61c2d449b1a9ec8c79bf1cdff6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_695788ff07e04a4da6ae9599122493e7"
          }
        },
        "3d047ba32cb741b6822f5c9a3d8073c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1a8f2b5d025948f9ac209ad07ad32b62",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:28&lt;00:00, 1.03B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6e23bee8f25c4cac96e84d97b90e9839"
          }
        },
        "81a2dc61c2d449b1a9ec8c79bf1cdff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "695788ff07e04a4da6ae9599122493e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a8f2b5d025948f9ac209ad07ad32b62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6e23bee8f25c4cac96e84d97b90e9839": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSkmkYKy9pzn",
        "outputId": "b7025ae4-dfd1-4c50-d9d6-afbdbc134f30"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Apr 24 01:49:46 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVOLbvYm-mI0"
      },
      "source": [
        "import os\n",
        "path = \"/content/drive/MyDrive/NLP2\"\n",
        "os.chdir(path)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjCFi23Z-tQu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eebe8a3d-a5c5-421f-fc8b-c09d6e13a1e5"
      },
      "source": [
        "! pip install transformers\n",
        "! pip install seqeval\n",
        "import pickle as pkl\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import chain\n",
        "import torch\n",
        "import transformers\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertForTokenClassification, AutoTokenizer\n",
        "from tqdm import tqdm, trange\n",
        "from seqeval.metrics import f1_score,accuracy_score"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 37.1MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 51.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n",
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16172 sha256=cf75715bec1e14f9439b5597c7a4a843431493a690c3aa895cf354af3c343955\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqQH4wlI_FFC"
      },
      "source": [
        "train_dict = pkl.load(open(\"./train.pkl\", \"rb\"))\n",
        "val_dict = pkl.load(open(\"./val.pkl\", \"rb\"))\n",
        "test_dict = pkl.load(open(\"./test.pkl\", \"rb\"))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4Fy7FHm_OQ3",
        "outputId": "126889ef-957d-40ca-8204-d7fdc323b6b3"
      },
      "source": [
        "print(\"keys in train_dict:\", train_dict.keys())\n",
        "print(\"keys in val_dict:\", val_dict.keys())\n",
        "print(\"keys in test_dict:\", test_dict.keys())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keys in train_dict: dict_keys(['id', 'word_seq', 'tag_seq'])\n",
            "keys in val_dict: dict_keys(['id', 'word_seq', 'tag_seq'])\n",
            "keys in test_dict: dict_keys(['id', 'word_seq'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMtQj1_9LaD3",
        "outputId": "a7df901e-043e-40f0-c155-8356df5e4078"
      },
      "source": [
        "print(\"index:\", train_dict[\"id\"][0])\n",
        "print(*zip(train_dict[\"word_seq\"][0], train_dict[\"tag_seq\"][0]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "index: 0\n",
            "('Protection', 'O') ('of', 'O') ('calves', 'LIVESTOCK') ('against', 'O') ('fatal', 'O') ('enteric', 'DISEASE_OR_SYNDROME') ('colibacillosis', 'DISEASE_OR_SYNDROME') ('by', 'O') ('orally', 'GENE_OR_GENOME') ('administered', 'GENE_OR_GENOME') ('Escherichia', 'GENE_OR_GENOME') ('coli', 'GENE_OR_GENOME') ('K99', 'GENE_OR_GENOME') ('-', 'O') ('specific', 'CARDINAL') ('monoclonal', 'CARDINAL') ('antibody', 'CARDINAL') ('.', 'O') ('A', 'O') ('monoclonal', 'CHEMICAL') ('antibody', 'CHEMICAL') ('(', 'O') ('MCA', 'GENE_OR_GENOME') (')', 'O') ('to', 'O') ('enterotoxigenic', 'CHEMICAL') ('Escherichia', 'CHEMICAL') ('coli', 'CHEMICAL') ('K99', 'O') ('antigen', 'O') ('agglutinated', 'O') ('K99+', 'GENE_OR_GENOME') ('enterotoxigenic', 'GENE_OR_GENOME') ('E', 'GENE_OR_GENOME') ('.', 'O') ('coli', 'CHEMICAL') ('strains', 'CHEMICAL') ('B44', 'CHEMICAL') ('(', 'O') ('O9', 'O') (':', 'O') ('K30', 'O') (';', 'O') ('K99', 'O') (';', 'O') ('F41', 'O') (':', 'O') ('H-', 'O') (')', 'O') ('and', 'O') ('B41', 'CHEMICAL') ('(', 'O') ('O101', 'PRODUCT') (':', 'O') ('K99', 'O') (';', 'O') ('F41', 'O') (':', 'O') ('H-', 'O') (')', 'O') ('grown', 'O') ('at', 'O') ('37', 'QUANTITY') ('degrees', 'QUANTITY') ('C', 'O') ('but', 'O') ('not', 'O') ('at', 'O') ('18', 'QUANTITY') ('degrees', 'QUANTITY') ('C.', 'O') ('The', 'O') ('MCA', 'GENE_OR_GENOME') (',', 'O') ('which', 'O') ('was', 'O') ('characterized', 'O') ('as', 'O') ('immunoglobulin', 'GENE_OR_GENOME') ('G1', 'GENE_OR_GENOME') (',', 'O') ('reacted', 'O') ('specifically', 'O') ('with', 'O') ('K99', 'CHEMICAL') ('antigen', 'CHEMICAL') ('in', 'O') ('an', 'O') ('enzyme-linked', 'CHEMICAL') ('immunosorbent', 'CHEMICAL') ('assay', 'CHEMICAL') ('and', 'O') ('precipitated', 'O') ('radiolabeled', 'O') ('K99', 'CHEMICAL') ('antigen', 'CHEMICAL') ('.', 'O') ('A', 'O') ('total', 'O') ('of', 'O') ('45', 'O') ('colostrum', 'CHEMICAL') ('-fed', 'O') ('and', 'O') ('colostrum', 'CHEMICAL') ('-deprived', 'O') ('calves', 'LIVESTOCK') ('were', 'O') ('used', 'O') ('in', 'O') ('three', 'CARDINAL') ('separate', 'O') ('trials', 'O') ('to', 'O') ('determine', 'O') ('whether', 'O') ('the', 'O') ('orally', 'O') ('administered', 'O') ('K99-specific', 'O') ('MCA', 'GENE_OR_GENOME') ('would', 'O') ('prevent', 'O') ('diarrhea', 'DISEASE_OR_SYNDROME') ('caused', 'O') ('by', 'O') ('strain', 'O') ('B44', 'GENE_OR_GENOME')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCdYbV4xRbGG"
      },
      "source": [
        "#  tag2idx： tag内容 -> tag index\n",
        "#  添加了bert的special tokens([CLS],[SEP])，一共67个tag\n",
        "taglist = set(chain(*train_dict[\"tag_seq\"]))\n",
        "tag2idx = {}\n",
        "tag2idx['_t_pad_'] = 0\n",
        "tag2idx['[CLS]'] = 1\n",
        "tag2idx['[SEP]'] = 2\n",
        "for tag in taglist:\n",
        "  if tag not in tag2idx:\n",
        "    tag2idx[tag] = len(tag2idx)\n",
        "tag2idx['PAD'] = 67\n",
        "\n",
        "#  tags_vals保存每个tag index对应的tag内容\n",
        "tags_vals = list(tag2idx.keys())"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zxeYCHkUH5Z"
      },
      "source": [
        "train_sentences = [word for word in train_dict['word_seq']]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5DeGllraqbX"
      },
      "source": [
        "train_labels = [labelline for labelline in train_dict[\"tag_seq\"]]\n",
        "train_labels = [[tag2idx.get(l) for l in lab] for lab in train_labels]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUzkEeNyhRIh"
      },
      "source": [
        "val_sentences = [word for word in val_dict['word_seq']]\n",
        "val_labels = [labelline for labelline in val_dict[\"tag_seq\"]]\n",
        "val_labels = [[tag2idx.get(l) for l in lab] for lab in val_labels]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rHhAtiPazs5"
      },
      "source": [
        "model_name = 'bert-base-cased'\n",
        "MAX_LEN = 250\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "VALID_BATCH_SIZE = 16\n",
        "LEARNING_RATE = 3e-5\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSiRs8jtVWnA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212,
          "referenced_widgets": [
            "302da2af74444b6989883fb97ec5851c",
            "85292428dca6475c838466090d7e55f1",
            "f75477712e5743e3aebef192664d9eba",
            "0a6af3592f534589a2440e7e212d5c7c",
            "fb228d14bed344e5a1467e6cf0b04347",
            "634aa3c5777242ce9fba2d27533bc5eb",
            "1722e29bf20747f385ea01dc1173ba27",
            "1ead1fe8c1ca4a589cb83136f4dc9f4c",
            "c47efe53d2314e33a8841d8301975d87",
            "bcb65e11e2ac4775a5a872f068ed918d",
            "db40df458a924ee3aea66cb39c260b75",
            "83c1ea35d21445a1a2d7de700c14ebef",
            "f8f6c37791294c7b9cc2d965f7ecc406",
            "c7d2fa885cb7494297bff33dc37acf40",
            "6eb1a033374443cd8b6a9ef454fdd1e6",
            "45b388f133074941b3a4717f93af46fe",
            "b745333e6bb840a093adf602d420a82e",
            "73fcbf9eba0e42c8a442f65c484b09d9",
            "9582ac09d22b45dd9cd457cfdac8b330",
            "eb992faa6b65467099a1c4da15a2268a",
            "d6ff8e97851f45a388c8c655e66eb496",
            "cb1634601e1741c788e440e84c650f49",
            "9bec44b2ce7748b08f829256dd804ad1",
            "25fdeafc632d4e3286210e378363dd49",
            "5106b73dbaeb4559afe06f0216f77b9e",
            "45de8fd6877147c387c1d59146d0a4c2",
            "bd9e1a67829e498eaa910da673b3a446",
            "3d047ba32cb741b6822f5c9a3d8073c7",
            "81a2dc61c2d449b1a9ec8c79bf1cdff6",
            "695788ff07e04a4da6ae9599122493e7",
            "1a8f2b5d025948f9ac209ad07ad32b62",
            "6e23bee8f25c4cac96e84d97b90e9839"
          ]
        },
        "outputId": "cbd47377-a9bd-40b7-b0c0-f605142d9cac"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "302da2af74444b6989883fb97ec5851c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c47efe53d2314e33a8841d8301975d87",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b745333e6bb840a093adf602d420a82e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5106b73dbaeb4559afe06f0216f77b9e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYLOJcZAzSoL",
        "outputId": "f591d311-a964-4ab5-8f98-68e1102fa3bf"
      },
      "source": [
        "#  添加token 以免Berttokenizer把 '_w_pad_' 分裂成多个token\n",
        "tokenizer.add_tokens(['_w_pad_','_unk_'])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dty0mn4pkGeK",
        "outputId": "4dd9898e-c7d7-443e-9e4d-abd6a16b9eb2"
      },
      "source": [
        "#  可以参照这个例子，对于不在词汇表里的token，Berttokenizer会把通过他们分裂成多个token来处理\n",
        "#  这样label的数量和tokenize之后的token数量会对不上\n",
        "#  处理的方法是计算一个token分裂出来的子串的数量，然后把该token对应的label也延长相应的长度\n",
        "#  比如 \"calvas\" : \"O\"\n",
        "#     \"ca\", \"##lves\":  \"O\",\"O\"\n",
        "#  因为这个数据集里有大量不在词汇表里专业名词，所以这种情况还挺多的，可能用BioBERT或者Bertlarge效果会好一点\n",
        "tokenizer.tokenize(' '.join(train_dict['word_seq'][0]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Protection',\n",
              " 'of',\n",
              " 'ca',\n",
              " '##lves',\n",
              " 'against',\n",
              " 'fatal',\n",
              " 'enter',\n",
              " '##ic',\n",
              " 'co',\n",
              " '##li',\n",
              " '##ba',\n",
              " '##ci',\n",
              " '##llo',\n",
              " '##sis',\n",
              " 'by',\n",
              " 'oral',\n",
              " '##ly',\n",
              " 'administered',\n",
              " 'E',\n",
              " '##scher',\n",
              " '##ichi',\n",
              " '##a',\n",
              " 'co',\n",
              " '##li',\n",
              " 'K',\n",
              " '##9',\n",
              " '##9',\n",
              " '-',\n",
              " 'specific',\n",
              " 'mon',\n",
              " '##oc',\n",
              " '##lon',\n",
              " '##al',\n",
              " 'anti',\n",
              " '##body',\n",
              " '.',\n",
              " 'A',\n",
              " 'mon',\n",
              " '##oc',\n",
              " '##lon',\n",
              " '##al',\n",
              " 'anti',\n",
              " '##body',\n",
              " '(',\n",
              " 'MCA',\n",
              " ')',\n",
              " 'to',\n",
              " 'enter',\n",
              " '##oto',\n",
              " '##xi',\n",
              " '##genic',\n",
              " 'E',\n",
              " '##scher',\n",
              " '##ichi',\n",
              " '##a',\n",
              " 'co',\n",
              " '##li',\n",
              " 'K',\n",
              " '##9',\n",
              " '##9',\n",
              " 'anti',\n",
              " '##gen',\n",
              " 'a',\n",
              " '##gg',\n",
              " '##lut',\n",
              " '##inated',\n",
              " 'K',\n",
              " '##9',\n",
              " '##9',\n",
              " '+',\n",
              " 'enter',\n",
              " '##oto',\n",
              " '##xi',\n",
              " '##genic',\n",
              " 'E',\n",
              " '.',\n",
              " 'co',\n",
              " '##li',\n",
              " 'strains',\n",
              " 'B',\n",
              " '##44',\n",
              " '(',\n",
              " 'O',\n",
              " '##9',\n",
              " ':',\n",
              " 'K',\n",
              " '##30',\n",
              " ';',\n",
              " 'K',\n",
              " '##9',\n",
              " '##9',\n",
              " ';',\n",
              " 'F',\n",
              " '##41',\n",
              " ':',\n",
              " 'H',\n",
              " '-',\n",
              " ')',\n",
              " 'and',\n",
              " 'B',\n",
              " '##41',\n",
              " '(',\n",
              " 'O',\n",
              " '##10',\n",
              " '##1',\n",
              " ':',\n",
              " 'K',\n",
              " '##9',\n",
              " '##9',\n",
              " ';',\n",
              " 'F',\n",
              " '##41',\n",
              " ':',\n",
              " 'H',\n",
              " '-',\n",
              " ')',\n",
              " 'grown',\n",
              " 'at',\n",
              " '37',\n",
              " 'degrees',\n",
              " 'C',\n",
              " 'but',\n",
              " 'not',\n",
              " 'at',\n",
              " '18',\n",
              " 'degrees',\n",
              " 'C',\n",
              " '.',\n",
              " 'The',\n",
              " 'MCA',\n",
              " ',',\n",
              " 'which',\n",
              " 'was',\n",
              " 'characterized',\n",
              " 'as',\n",
              " 'im',\n",
              " '##mu',\n",
              " '##no',\n",
              " '##g',\n",
              " '##lo',\n",
              " '##bul',\n",
              " '##in',\n",
              " 'G',\n",
              " '##1',\n",
              " ',',\n",
              " 'reacted',\n",
              " 'specifically',\n",
              " 'with',\n",
              " 'K',\n",
              " '##9',\n",
              " '##9',\n",
              " 'anti',\n",
              " '##gen',\n",
              " 'in',\n",
              " 'an',\n",
              " 'enzyme',\n",
              " '-',\n",
              " 'linked',\n",
              " 'im',\n",
              " '##mu',\n",
              " '##nos',\n",
              " '##or',\n",
              " '##bent',\n",
              " 'ass',\n",
              " '##ay',\n",
              " 'and',\n",
              " 'pre',\n",
              " '##ci',\n",
              " '##pit',\n",
              " '##ated',\n",
              " 'radio',\n",
              " '##la',\n",
              " '##bel',\n",
              " '##ed',\n",
              " 'K',\n",
              " '##9',\n",
              " '##9',\n",
              " 'anti',\n",
              " '##gen',\n",
              " '.',\n",
              " 'A',\n",
              " 'total',\n",
              " 'of',\n",
              " '45',\n",
              " 'co',\n",
              " '##los',\n",
              " '##tr',\n",
              " '##um',\n",
              " '-',\n",
              " 'fed',\n",
              " 'and',\n",
              " 'co',\n",
              " '##los',\n",
              " '##tr',\n",
              " '##um',\n",
              " '-',\n",
              " 'deprived',\n",
              " 'ca',\n",
              " '##lves',\n",
              " 'were',\n",
              " 'used',\n",
              " 'in',\n",
              " 'three',\n",
              " 'separate',\n",
              " 'trials',\n",
              " 'to',\n",
              " 'determine',\n",
              " 'whether',\n",
              " 'the',\n",
              " 'oral',\n",
              " '##ly',\n",
              " 'administered',\n",
              " 'K',\n",
              " '##9',\n",
              " '##9',\n",
              " '-',\n",
              " 'specific',\n",
              " 'MCA',\n",
              " 'would',\n",
              " 'prevent',\n",
              " 'di',\n",
              " '##ar',\n",
              " '##r',\n",
              " '##hea',\n",
              " 'caused',\n",
              " 'by',\n",
              " 'strain',\n",
              " 'B',\n",
              " '##44']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai0Cdqp7a_WC"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, tokenizer, sentences, labels, max_len):\n",
        "        self.len = len(sentences)\n",
        "        self.sentences = sentences\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        sentence = self.sentences[index]\n",
        "        s = str(' '.join(sentence))\n",
        "        label_s = self.labels[index]\n",
        "        new_labels = []\n",
        "        new_labels.extend([1])  # 添加[CLS]对应的label\n",
        "        for word, label in zip(sentence, label_s):\n",
        "          tokenized_word = tokenizer.tokenize(word)\n",
        "          count_subwords = len(tokenized_word)  # 计算tokenize之后的subwords数量\n",
        "          new_labels.extend([label] * count_subwords)  # 相应地延长对应的label\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            s,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=MAX_LEN,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        new_labels.extend([2])  # 添加[SEP]对应的label\n",
        "        #  对于后面的padding部分也添加label 保证label的长度和padding后的句子长度一致 (67:'PAD')\n",
        "        new_labels.extend([67]*MAX_LEN)\n",
        "        new_labels=new_labels[:MAX_LEN]\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'tags': torch.tensor(new_labels, dtype=torch.long)\n",
        "        } \n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKb5yDvmU1MM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04bb16c6-9d01-44e5-a7ac-d5518cb63c7c"
      },
      "source": [
        "# Creating the dataset and dataloader for the neural network\n",
        "print(\"TRAIN Dataset: {}\".format(len(train_sentences)))\n",
        "print(\"TEST Dataset: {}\".format(len(val_sentences)))\n",
        "\n",
        "training_set = CustomDataset(tokenizer, train_sentences, train_labels, MAX_LEN)  # 训练集\n",
        "testing_set = CustomDataset(tokenizer, val_sentences, val_labels, MAX_LEN)  # 验证集"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN Dataset: 23600\n",
            "TEST Dataset: 2950\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP0EHrjkiA7i"
      },
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': False,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': False,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJIXIC_BxzRs",
        "collapsed": true,
        "outputId": "4ef75f65-3af3-412d-9815-8f4c65cc5593"
      },
      "source": [
        "# 示例\n",
        "training_set[0]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': tensor([  101,  8063,  1104, 11019, 14455,  1222, 11874,  3873,  1596,  1884,\n",
              "          2646,  2822,  6617,  6643,  4863,  1118,  9619,  1193,  8318,   142,\n",
              "         27826, 11985,  1161,  1884,  2646,   148,  1580,  1580,   118,  2747,\n",
              "         19863, 13335,  4934,  1348,  2848, 14637,   119,   138, 19863, 13335,\n",
              "          4934,  1348,  2848, 14637,   113, 24955,   114,  1106,  3873, 12355,\n",
              "          8745, 19438,   142, 27826, 11985,  1161,  1884,  2646,   148,  1580,\n",
              "          1580,  2848,  4915,   170,  9705, 25937, 16868,   148,  1580,  1580,\n",
              "           116,  3873, 12355,  8745, 19438,   142,   119,  1884,  2646, 21116,\n",
              "           139, 25041,   113,   152,  1580,   131,   148, 13144,   132,   148,\n",
              "          1580,  1580,   132,   143, 25892,   131,   145,   118,   114,  1105,\n",
              "           139, 25892,   113,   152, 10424,  1475,   131,   148,  1580,  1580,\n",
              "           132,   143, 25892,   131,   145,   118,   114,  4215,  1120,  3413,\n",
              "          4842,   140,  1133,  1136,  1120,  1407,  4842,   140,   119,  1109,\n",
              "         24955,   117,  1134,  1108,  6858,  1112, 13280, 13601,  2728,  1403,\n",
              "          2858, 27515,  1394,   144,  1475,   117, 15510,  4418,  1114,   148,\n",
              "          1580,  1580,  2848,  4915,  1107,  1126,  8744,   118,  5128, 13280,\n",
              "         13601, 14226,  1766, 19145,  3919,  4164,  1105,  3073,  6617, 18965,\n",
              "          2913,  2070,  1742,  8511,  1174,   148,  1580,  1580,  2848,  4915,\n",
              "           119,   138,  1703,  1104,  2532,  1884,  8867, 18062,  1818,   118,\n",
              "          7672,  1105,  1884,  8867, 18062,  1818,   118, 19576, 11019, 14455,\n",
              "          1127,  1215,  1107,  1210,  2767,  7356,  1106,  4959,  2480,  1103,\n",
              "          9619,  1193,  8318,   148,  1580,  1580,   118,  2747, 24955,  1156,\n",
              "          3843,  4267,  1813,  1197, 13836,  2416,  1118, 10512,   139, 25041,\n",
              "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
              " 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'tags': tensor([ 1, 36, 36, 53, 53, 36, 36,  7,  7,  7,  7,  7,  7,  7,  7, 36, 17, 17,\n",
              "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 36, 22, 22, 22, 22, 22, 22, 22,\n",
              "         36, 36, 58, 58, 58, 58, 58, 58, 36, 17, 36, 36, 58, 58, 58, 58, 58, 58,\n",
              "         58, 58, 58, 58, 36, 36, 36, 36, 36, 36, 36, 36, 36, 17, 17, 17, 17, 17,\n",
              "         17, 17, 17, 17, 36, 58, 58, 58, 58, 58, 36, 36, 36, 36, 36, 36, 36, 36,\n",
              "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 58, 58, 36, 31, 31, 31, 36, 36,\n",
              "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,  6,  6, 36, 36, 36, 36,  6,\n",
              "          6, 36, 36, 36, 17, 36, 36, 36, 36, 36, 17, 17, 17, 17, 17, 17, 17, 17,\n",
              "         17, 36, 36, 36, 36, 58, 58, 58, 58, 58, 36, 36, 58, 58, 58, 58, 58, 58,\n",
              "         58, 58, 58, 58, 36, 36, 36, 36, 36, 36, 36, 36, 36, 58, 58, 58, 58, 58,\n",
              "         36, 36, 36, 36, 36, 58, 58, 58, 58, 36, 36, 36, 58, 58, 58, 58, 36, 36,\n",
              "         53, 53, 36, 36, 36, 22, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
              "         36, 36, 17, 36, 36,  7,  7,  7,  7, 36, 36, 36, 17, 17,  2, 67, 67, 67,\n",
              "         67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIRiNdoay5o4"
      },
      "source": [
        "BertForTokenClassification \n",
        "\n",
        "https://huggingface.co/transformers/model_doc/bert.html#bertfortokenclassification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwOi99yYHKzf",
        "outputId": "172b8ef4-add9-4669-c624-7bbc4a827b6f"
      },
      "source": [
        "model = BertForTokenClassification.from_pretrained(\n",
        "    \"bert-base-cased\",\n",
        "    num_labels=len(tag2idx),  # 67分类\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXuQ3XS0N1NX",
        "outputId": "b3a9fd5d-6439-445a-a66d-221eebbcdeff"
      },
      "source": [
        "model.resize_token_embeddings(len(tokenizer))  # add_token之后相应的resize一下embedding的维度\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForTokenClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28998, 768)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=68, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OqRAovXOGVj"
      },
      "source": [
        "FULL_FINETUNING = True\n",
        "if FULL_FINETUNING:\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "else:\n",
        "    param_optimizer = list(model.classifier.named_parameters()) \n",
        "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "optimizer = torch.optim.Adam(optimizer_grouped_parameters, lr=LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC134CycSRYv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e5cab87-2966-464a-bb5d-bc19651ac37a"
      },
      "source": [
        "epochs = 15\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "    # TRAINING\n",
        "    model.train()\n",
        "    tr_loss = 0\n",
        "    tr_pred , tr_true_labels = [], []\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    for step, batch in enumerate(training_loader):\n",
        "        # add batch to gpu\n",
        "        b_input_ids = batch['ids'].to(device)\n",
        "        b_input_mask = batch['mask'].to(device)\n",
        "        b_labels = batch['tags'].to(device)\n",
        "        # forward pass\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "        loss = outputs['loss']\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        # track train loss\n",
        "        tr_loss += loss.item()\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        model.zero_grad()\n",
        "        # Move logits and labels to CPU\n",
        "        tr_logits = outputs['logits'].detach().cpu().numpy()\n",
        "        tr_label = b_labels.to('cpu').numpy()\n",
        "        tr_pred.extend([list(p) for p in np.argmax(tr_logits, axis=2)])\n",
        "        tr_true_labels.extend(tr_label)\n",
        "\n",
        "    # print train loss per epoch\n",
        "    print(\"Train loss: {}\".format(tr_loss / len(training_loader)))\n",
        "    tr_pred_tags = [tags_vals[p_i] for p, l in zip(tr_pred, tr_true_labels) for p_i, l_i in zip(p, l) if tags_vals[l_i] != \"PAD\"]\n",
        "    train_tags = [tags_vals[l_i] for l in tr_true_labels for l_i in l if tags_vals[l_i] != \"PAD\"]\n",
        "    train_acc = accuracy_score(tr_pred_tags, train_tags)\n",
        "    print(\"Train Accuracy: {}\".format(train_acc))\n",
        "\n",
        "\n",
        "    # VALIDATION\n",
        "    model.eval()\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    predictions , true_labels = [], []\n",
        "    for batch in testing_loader:\n",
        "        b_input_ids = batch['ids'].to(device)\n",
        "        b_input_mask = batch['mask'].to(device)\n",
        "        b_labels = batch['tags'].to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "        logits = outputs['logits'].detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        eval_loss += outputs['loss'].mean().item()\n",
        "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "        true_labels.extend(label_ids)\n",
        "        \n",
        "    eval_loss = eval_loss/len(testing_loader)\n",
        "\n",
        "    print(\"Validation loss: {}\".format(eval_loss))\n",
        "    pred_tags = [tags_vals[p_i] for p, l in zip(predictions, true_labels)\n",
        "                                 for p_i, l_i in zip(p, l) if tags_vals[l_i] != \"PAD\"]\n",
        "    valid_tags = [tags_vals[l_i] for l in true_labels\n",
        "                                  for l_i in l if tags_vals[l_i] != \"PAD\"]\n",
        "    valid_acc = accuracy_score(pred_tags, valid_tags)\n",
        "    print(\"Validation Accuracy: {}\".format(valid_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/15 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.7326920686294716\n",
            "Train Accuracy: 0.8022816069538605\n",
            "Validation loss: 0.5275163590908051\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   7%|▋         | 1/15 [08:40<2:01:32, 520.92s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8478923971446044\n",
            "Train loss: 0.4814035117545425\n",
            "Train Accuracy: 0.8596164636330771\n",
            "Validation loss: 0.45480387162517855\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  13%|█▎        | 2/15 [17:21<1:52:50, 520.83s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8673142487380939\n",
            "Train loss: 0.39775182815586646\n",
            "Train Accuracy: 0.8821507032777565\n",
            "Validation loss: 0.4271253922501126\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  20%|██        | 3/15 [26:04<1:44:18, 521.55s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8758871681126299\n",
            "Train loss: 0.3397463687915143\n",
            "Train Accuracy: 0.8982986681784838\n",
            "Validation loss: 0.41438167417371596\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  27%|██▋       | 4/15 [34:54<1:36:05, 524.11s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8809329221424069\n",
            "Train loss: 0.2941048635740267\n",
            "Train Accuracy: 0.9109585791847358\n",
            "Validation loss: 0.40953979556624953\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  33%|███▎      | 5/15 [43:41<1:27:28, 524.89s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8844619576702755\n",
            "Train loss: 0.2573375866261278\n",
            "Train Accuracy: 0.9211067922640265\n",
            "Validation loss: 0.40794235935082307\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  40%|████      | 6/15 [52:27<1:18:47, 525.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8886081536243213\n",
            "Train loss: 0.22628673028735932\n",
            "Train Accuracy: 0.9300339761594344\n",
            "Validation loss: 0.41440189666039234\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  47%|████▋     | 7/15 [1:01:12<1:09:59, 524.98s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8904745963677304\n",
            "Train loss: 0.1998931522049555\n",
            "Train Accuracy: 0.9375195277035748\n",
            "Validation loss: 0.4312961973048545\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  53%|█████▎    | 8/15 [1:10:02<1:01:26, 526.67s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8876263074917665\n",
            "Train loss: 0.17723059545202954\n",
            "Train Accuracy: 0.9439125794516096\n",
            "Validation loss: 0.4391350264484818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  60%|██████    | 9/15 [1:18:50<52:41, 526.97s/it]  "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8906522637631451\n",
            "Train loss: 0.15757437568248772\n",
            "Train Accuracy: 0.9496505987015728\n",
            "Validation loss: 0.4444419260766055\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  67%|██████▋   | 10/15 [1:27:37<43:54, 526.89s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8938633681623768\n",
            "Train loss: 0.14120330273862777\n",
            "Train Accuracy: 0.9545122812166918\n",
            "Validation loss: 0.4624579313639048\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  73%|███████▎  | 11/15 [1:36:24<35:07, 526.98s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8930554490590173\n",
            "Train loss: 0.12599028873593018\n",
            "Train Accuracy: 0.9589465450950031\n",
            "Validation loss: 0.4583782102610614\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  80%|████████  | 12/15 [1:45:13<26:22, 527.54s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8964236488394579\n",
            "Train loss: 0.1120664231115725\n",
            "Train Accuracy: 0.9633069629977914\n",
            "Validation loss: 0.4787542662105045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  87%|████████▋ | 13/15 [1:53:56<17:32, 526.39s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8970295881669774\n",
            "Train loss: 0.1008669943435163\n",
            "Train Accuracy: 0.9667634687698126\n",
            "Validation loss: 0.47672764497834286\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  93%|█████████▎| 14/15 [2:02:39<08:45, 525.22s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8997376133097191\n",
            "Train loss: 0.09146094284345949\n",
            "Train Accuracy: 0.9697278238315452\n",
            "Validation loss: 0.48220225814226514\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 15/15 [2:11:24<00:00, 525.64s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9004782058211319\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBYRXHktUhXh"
      },
      "source": [
        "output_model = './model/model.pth'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PQS2w0MNApX"
      },
      "source": [
        "def save(model, optimizer):\n",
        "    # save\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict()\n",
        "    }, output_model)\n",
        "    print('The model has been saved')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isYw7_cpLAqU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "958ed1b2-cac8-4a0c-be28-e743b6667d6b"
      },
      "source": [
        "save(model, optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best model has been saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaAkVHli9bU5",
        "outputId": "fcad993e-7271-43f9-f2a1-5405d50441e5"
      },
      "source": [
        "#  预测testset\n",
        "\n",
        "model.eval()\n",
        "total_labels , total_tokens = [], []\n",
        "for i in trange(len(test_dict['word_seq'])):\n",
        "    if i not in [528, 2485]:\n",
        "      decoded_tokens, tag_predicted = [], []\n",
        "\n",
        "      # push the text into GPU, get the output of the prediction, push it to CPU\n",
        "      tokenized_index = tokenizer.encode(str(' '.join(word for word in test_dict['word_seq'][i] if word != '_w_pad_')),add_special_tokens=True,max_length=512,padding=False,truncation=True)\n",
        "      input_text = torch.tensor([tokenized_index]).cuda()\n",
        "      with torch.no_grad():\n",
        "          output = model(input_text)\n",
        "      tag_predicted = np.argmax(output[0].to('cpu').numpy(), axis=2)[0]\n",
        "      decoded_tokens = tokenizer.convert_ids_to_tokens(input_text.to('cpu').numpy()[0])\n",
        "\n",
        "      # Merge the divided tokens and tags together\n",
        "      new_tokens, new_labels = [], []\n",
        "      for token, tag in zip(decoded_tokens, tag_predicted):\n",
        "          if token in ['[PAD]','[CLS]','[SEP]']:\n",
        "              continue\n",
        "          else:\n",
        "              new_tokens.append(token)\n",
        "              new_labels.append(tags_vals[tag])\n",
        "\n",
        "      total_labels += new_labels\n",
        "      total_tokens += new_tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2950/2950 [00:39<00:00, 75.54it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnPbpwoF-Hg8",
        "outputId": "474447ad-9203-4f63-9a4d-c55db8871bda"
      },
      "source": [
        "len(total_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "499778"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5i4tEvyYy_J"
      },
      "source": [
        "# for i in range(len(m)):\n",
        "#   if m[i] != k[i]:\n",
        "#     print(i)            528  2485"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXPgjOL3jDlC"
      },
      "source": [
        "# test_dict['word_seq'][1012][80:84]  #'\\ufeff\\ufeff'\n",
        "# w =  '\\ufeff\\ufeff'\n",
        "# k = tokenizer.tokenize(w)\n",
        "# len(k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRr7fhh8s9Ml"
      },
      "source": [
        "这里检查了一下total_labels的长度和要求的输出的长度对不上，然后逐行比较了一下每行的label数量和应该有的token数量，发现问题出现在测试集的第528行和第2485行，这两行Tokenize之后的长度直接超过512了..\n",
        "\n",
        "原因是这两行压根不是英语，是两行俄语。\n",
        "\n",
        "处理的方法是直接把这两行所有的tag都预测成O算了。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3z_MooVYFho_",
        "outputId": "2291e806-6c7d-4b38-cc68-d8eca0a055c7"
      },
      "source": [
        "# 这里我是一行一行输出到dataframe里面的纯浪费时间,改成直接用total_labels给tag一列赋值就快了\n",
        "# 但是要确认total_labels的长度和正常的输出长度一样(349105)\n",
        "\n",
        "result = pd.DataFrame(columns=['id', 'count','tag'])\n",
        "count = 0\n",
        "for i in trange(len(test_dict['word_seq'])):\n",
        "  if i not in [528, 2485]:\n",
        "    for j in range(len(test_dict['word_seq'][i])):\n",
        "      if test_dict['word_seq'][i][j] != \"_w_pad_\":\n",
        "        tokenized_word = tokenizer.tokenize(test_dict['word_seq'][i][j])\n",
        "        count_subwords = len(tokenized_word)\n",
        "        id1 = str(i)+\"_\"+str(j)\n",
        "        # 对于被分裂成多个subtoken的token直接取第一个subtoken的预测label值作为tag\n",
        "        result = result.append({'id':id1, 'count':count_subwords, 'tag': total_labels[count]},ignore_index=True)\n",
        "        count += count_subwords\n",
        "  else:\n",
        "    for j in range(len(test_dict['word_seq'][i])):\n",
        "      id1 = str(i)+\"_\"+str(j)\n",
        "      result = result.append({'id':id1, 'count':0, 'tag': 'O'},ignore_index=True)  # 对于line528&line2485直接全部预测成'O'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 528/2950 [04:54<28:28,  1.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "528\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 2485/2950 [1:00:42<22:34,  2.91s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2485\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2950/2950 [1:24:58<00:00,  1.73s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "nQsU1xQEbMuD",
        "outputId": "19ed11e3-ea66-4b30-fb6a-3db5feac69ee"
      },
      "source": [
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>count</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0_0</td>\n",
              "      <td>4</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0_1</td>\n",
              "      <td>2</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0_2</td>\n",
              "      <td>1</td>\n",
              "      <td>IMMUNE_RESPONSE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0_3</td>\n",
              "      <td>1</td>\n",
              "      <td>IMMUNE_RESPONSE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0_4</td>\n",
              "      <td>1</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349100</th>\n",
              "      <td>2949_123</td>\n",
              "      <td>1</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349101</th>\n",
              "      <td>2949_124</td>\n",
              "      <td>1</td>\n",
              "      <td>THERAPEUTIC_OR_PREVENTIVE_PROCEDURE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349102</th>\n",
              "      <td>2949_125</td>\n",
              "      <td>1</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349103</th>\n",
              "      <td>2949_126</td>\n",
              "      <td>1</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349104</th>\n",
              "      <td>2949_127</td>\n",
              "      <td>1</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>349105 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              id count                                 tags\n",
              "0            0_0     4                                    O\n",
              "1            0_1     2                                    O\n",
              "2            0_2     1                      IMMUNE_RESPONSE\n",
              "3            0_3     1                      IMMUNE_RESPONSE\n",
              "4            0_4     1                                    O\n",
              "...          ...   ...                                  ...\n",
              "349100  2949_123     1                                    O\n",
              "349101  2949_124     1  THERAPEUTIC_OR_PREVENTIVE_PROCEDURE\n",
              "349102  2949_125     1                                    O\n",
              "349103  2949_126     1                                    O\n",
              "349104  2949_127     1                                    O\n",
              "\n",
              "[349105 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-p872BP_Hih"
      },
      "source": [
        "pd.DataFrame(result, columns = ['id', 'tags']).to_csv(\"prediction.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIszVc0Kvez8"
      },
      "source": [
        "另外一种方法：对于被分裂成多个subtokens的token，取subtokens中出现最多的label(众数）作为预测值。\n",
        "\n",
        "但是试了一次效果没有直接取第一个subtoken的label作为预测值的效果好。\n",
        "\n",
        "不太确定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "zF-2pcPUpxlF",
        "outputId": "8fc88f85-9e7c-4861-b571-7041d40749bf"
      },
      "source": [
        "# result = pd.DataFrame(columns=['id', 'count','tag'])\n",
        "# count = 0\n",
        "# for i in trange(len(test_dict['word_seq'])):\n",
        "#   if i not in [528, 2485]:\n",
        "#     for j in range(len(test_dict['word_seq'][i])):\n",
        "#       if test_dict['word_seq'][i][j] not in  [\"_w_pad_\",\"\\ufeff\\ufeff\"]:  # 第1102行有个\"\\ufeff\\ufeff\"会导致len(tokenized_word)=0\n",
        "#         tokenized_word = tokenizer.tokenize(test_dict['word_seq'][i][j])\n",
        "#         count_subwords = len(tokenized_word) # if len(tokenized_word) != 0 else 1\n",
        "#         id1 = str(i)+\"_\"+str(j)\n",
        "#         count_range = count + count_subwords\n",
        "#         label = max(set(total_labels[count:count_range]), key = total_labels[count:count_range].count)\n",
        "#         result = result.append({'id':id1, 'count':count_subwords, 'tag': label},ignore_index=True)\n",
        "#         count += count_subwords\n",
        "#   else:\n",
        "#     print(i)\n",
        "#     for j in range(len(test_dict['word_seq'][i])):\n",
        "#       id1 = str(i)+\"_\"+str(j)\n",
        "#       result = result.append({'id':id1, 'count':0, 'tag': 'O'},ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-47-d20d9fbb9e3d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ----------------------\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}